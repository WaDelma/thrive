{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.patches as patches\n",
    "import sys\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "%run colors.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takes JMH output and does some mangling on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fromJMH(df):\n",
    "    df = df.rename(columns={\n",
    "        \"Param: density\": \"Density\",\n",
    "        \"Param: size\": \"Size\",\n",
    "        \"Score Error (99.9%)\": \"Error\"\n",
    "    })\n",
    "    r = df.Benchmark.str.extract(\".*_(.*)\\.(.*)\")\n",
    "    r.columns = ['Structure', 'Benchmark']\n",
    "    r.Structure = r.Structure\n",
    "    r = r.assign(Benchmark = r.apply(lambda x: x[1].replace(x[0], ''), 1))\n",
    "    df2 = df.drop(\"Benchmark\", 1).join(r)\n",
    "    df2 = df2[df2.Structure.isin(['Trie1j64']) == False]\n",
    "    df2 = df2.replace({\"Structure\": {\n",
    "        'Trie1': 'IntChamp32Kotlin',\n",
    "        'Trie1j': 'IntChamp32Java',\n",
    "        'Trie2': 'IntHamt32Kotlin',\n",
    "        'Trie2j': 'IntHamt32Java',\n",
    "        'Trie2j16': 'IntHamt16Java',\n",
    "        'Trie2j64': 'IntHamt64Java',\n",
    "        'Trie3': 'IntImplicitKeyHamtKotlin',\n",
    "        'ClojurePersistentHashMap': 'ClojureHashMap',\n",
    "        'ClojurePersistentTreeMap': 'ClojureTreeMap',\n",
    "        'PaguroPersistentTreeMap': 'PaguroTreeMap',\n",
    "        'PaguroPersistentHashMap': 'PaguroHashMap',\n",
    "        'RadixBalancedTreeRedux': 'RadixTreeRedux',\n",
    "        'RadixBalancedTree': 'RadixTree',\n",
    "        'ClojureRrbMap': 'ClojureVectorMap'\n",
    "    }, \"Benchmark\": {\n",
    "        'missingGet': 'missingAccess',\n",
    "        'hittingGet': 'hittingAccess',\n",
    "        'hittingGetLinear': 'hittingAccessSequential',\n",
    "        'iterateLinear': 'iterateSequential',\n",
    "        'insertLinear': 'insertSequential',\n",
    "    }})\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of differences of two servers test were run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = fromJMH(pd.read_csv(\"old server/results.csv\"))\n",
    "results1 = results1[results1.Structure.isin(['IntHamt64Java']) == False]\n",
    "a = pd.read_csv(\"new server/results1.csv\")\n",
    "b = pd.read_csv(\"new server/results2.csv\")\n",
    "c = pd.read_csv(\"new server/results3.csv\")\n",
    "newresults = fromJMH(a.append(b).append(c).reset_index(drop=True))\n",
    "\n",
    "bench = \"hittingAccess\"\n",
    "\n",
    "a = \"PaguroTreeMap\"\n",
    "b = \"PaguroHashMap\"\n",
    "\n",
    "l =  results1.Density == 0.5\n",
    "ptm1 = results1[(results1.Benchmark == bench) & (results1.Structure == a) & l]\n",
    "ptm1 = ptm1.drop([\"Mode\", \"Threads\", \"Samples\", \"Unit\", \"Benchmark\", \"Structure\"], 1).reset_index(drop=True)\n",
    "\n",
    "phm1 = results1[(results1.Benchmark == bench) & (results1.Structure == b) & l]\n",
    "phm1 = phm1.drop([\"Mode\", \"Threads\", \"Samples\", \"Unit\", \"Benchmark\", \"Structure\"], 1).reset_index(drop=True)\n",
    "\n",
    "ptm1.Score = ptm1.Score / phm1.Score\n",
    "\n",
    "ptm2 = newresults[(newresults.Benchmark == bench) & (newresults.Structure == a)]\n",
    "ptm2 = ptm2.drop([\"Mode\", \"Threads\", \"Samples\", \"Unit\", \"Benchmark\", \"Structure\"], 1).reset_index(drop=True)\n",
    "\n",
    "phm2 = newresults[(newresults.Benchmark == bench) & (newresults.Structure == b)]\n",
    "phm2 = phm2.drop([\"Mode\", \"Threads\", \"Samples\", \"Unit\", \"Benchmark\", \"Structure\"], 1).reset_index(drop=True)\n",
    "\n",
    "ptm2.Score = ptm2.Score / phm2.Score\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "ptm1.plot(\"Size\", \"Score\", logx=True, ax=ax, label=\"old\")\n",
    "ptm2.plot(\"Size\", \"Score\", logx=True, ax=ax, label=\"new\")\n",
    "\n",
    "ptm1.Score = ptm1.Score / ptm2.Score\n",
    "\n",
    "ptm1.plot(\"Size\", \"Score\", logx=True)\n",
    "\n",
    "\n",
    "# plt.plot(ptm1[\"Size\"], ptm1[\"Score\"]/phm1[\"Score\"])\n",
    "# plt.plot(ptm1[\"Size\"], ptm2[\"Score\"]/phm2[\"Score\"])\n",
    "\n",
    "# l = results1.Density.isnull() | (results1.Density == 0.5)\n",
    "# s = \"IntHamt64Java\"\n",
    "# a = results1[(results1.Benchmark == \"hittingAccess\") & results1.Structure.isin([s]) & l].drop([\"Mode\", \"Threads\", \"Samples\", \"Unit\"], 1)\n",
    "# b = results2[(results2.Benchmark == \"hitting\") & results2.Structure.isin([s])].drop([\"Mode\", \"Threads\", \"Samples\", \"Unit\"], 1)\n",
    "# plt.plot(b[\"Score\"].reset_index(drop=True) / a[\"Score\"].reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the results of benchmarks. Some extra munging had to be done as they weren't done neatly in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"old server/results.csv\")\n",
    "extended = pd.read_csv(\"old server/resultsAdditionalAndUpdatedScala.csv\")\n",
    "preciseResults = fromJMH(pd.read_csv(\"old server/resultsPrecise.csv\"))\n",
    "extended.replace(\"Scala\", \"ScalaV2\", inplace=True, regex=True)\n",
    "results = results.append(extended[\n",
    "    extended.Benchmark.str.contains(\"ScalaV2\") |\n",
    "    extended.Benchmark.str.contains(\"RadixBalancedTree\") |\n",
    "    extended.Benchmark.str.contains(\"PaguroVectorMap\")\n",
    "]).reset_index(drop=True)\n",
    "up = extended[\n",
    "    (extended.Benchmark.str.contains(\"ScalaV2\") == False) &\n",
    "    (extended.Benchmark.str.contains(\"RadixBalancedTree\") == False) &\n",
    "    (extended.Benchmark.str.contains(\"PaguroVectorMap\") == False)\n",
    "]\n",
    "def key(row): return row['Benchmark'] + str(row['Param: size']) + str(row['Param: density'])\n",
    "m = {}\n",
    "for index, row in up.iterrows():\n",
    "    m[key(row)] = (row['Score'], row['Score Error (99.9%)'])\n",
    "\n",
    "results = results.apply(lambda row: {\n",
    "                                'Benchmark': row['Benchmark'],\n",
    "                                'Mode': row['Mode'],\n",
    "                                'Threads': row['Threads'],\n",
    "                                'Samples': row['Samples'],\n",
    "                                'Score': m.get(key(row), (row['Score'], row['Score Error (99.9%)']))[0],\n",
    "                                'Score Error (99.9%)': m.get(key(row), (row['Score'], row['Score Error (99.9%)']))[1],\n",
    "                                'Unit': row['Unit'],\n",
    "                                'Param: density': row['Param: density'],\n",
    "                                'Param: size': row['Param: size'],\n",
    "                            }\n",
    "                        , axis = 1, result_type = \"expand\")\n",
    "results2 = fromJMH(results)\n",
    "results2 = results2[results2.Structure.isin(['IntHamt16Java', 'IntHamt64Java']) == False]\n",
    "\n",
    "results2[\n",
    "    results.Benchmark.str.contains(\"Scala\") &\n",
    "    (results.Benchmark.str.contains(\"V2\") == False)\n",
    "    & results.Benchmark.str.contains(\"BenchmarkGet_\")\n",
    "    & results.Benchmark.str.contains(\"hitting\")\n",
    "].head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables used later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = results2[\"Benchmark\"].unique()\n",
    "benchmarks.sort()\n",
    "benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmarks = ['hittingAccess', 'insert', 'iterate',\n",
    "              'hittingAccessSequential', 'insertSequential', 'iterateSequential',\n",
    "              'missingAccess']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = results2[\"Structure\"].unique()\n",
    "structures.sort()\n",
    "structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List data structures in the order of linelikeness in logarithm scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"Benchmark\", \"Structure\", \"Line Error\"])\n",
    "for benchmark in benchmarks:\n",
    "    iterate = results2[results2.Benchmark == benchmark].drop(\"Benchmark\", 1)\n",
    "    if \"Sequential\" not in benchmark:\n",
    "        iterate = iterate[iterate.Density == 0.5]\n",
    "    iterate = iterate.drop(\"Density\", 1)\n",
    "    for name, group in iterate.groupby(\"Structure\"):\n",
    "        regr = linear_model.LinearRegression()\n",
    "#         print(group.Size, group.Score)\n",
    "        x = np.log(group.Size.values.reshape(-1, 1))\n",
    "        y = np.log(group.Score.values.reshape(-1, 1))\n",
    "        regr.fit(x, y)\n",
    "        # Yikes! Not using a testing set!!\n",
    "        # But I don't care if I am generalizing or not. I just want to know how \"line like\" the data is.\n",
    "        # After log scaling that is\n",
    "        pred = regr.predict(x)\n",
    "#         plt.scatter(x, y,  color='black')\n",
    "#         plt.plot(x, pred, color='blue', linewidth=3)\n",
    "#         plt.xticks(())\n",
    "#         plt.yticks(())\n",
    "#         plt.show()\n",
    "        err = mean_squared_error(y, pred)\n",
    "        if \"Access\" in benchmark:\n",
    "            err = 2 * err\n",
    "        df = df.append({\n",
    "            \"Benchmark\": benchmark,\n",
    "            \"Structure\": name,\n",
    "            \"Line Error\": err\n",
    "        }, ignore_index=True)\n",
    "df2 = pd.DataFrame(columns = [\"Structure\", \"Error\"])\n",
    "for name, group in df.groupby(\"Structure\"):\n",
    "    df2 = df2.append({\n",
    "        \"Structure\": name,\n",
    "        \"Error\": np.sqrt(np.sum(group[\"Line Error\"].map(lambda x: x ** 2)))\n",
    "    }, ignore_index=True)\n",
    "df2.sort_values(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main visualisation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(results3, normalizeTo = False, error = False, filename = \"results\", render = True, logx = True, logy = None, densities = [0.5], stats = False):\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    print(f\"visualising {filename}\")\n",
    "    if logy == None:\n",
    "        logy = normalizeTo == False\n",
    "    if normalizeTo != False:\n",
    "        ylabel = \"savings (in %)\"\n",
    "    else:\n",
    "        ylabel = \"ops/s\"\n",
    "    fig, ax = plt.subplots(3, 3, sharex=False, sharey=False, figsize=(15,15))\n",
    "    axs = ax.flatten()\n",
    "    maxs = [0, 0, 0, 0, 0, 0, 0]\n",
    "    mins = [sys.maxsize, sys.maxsize, sys.maxsize, sys.maxsize, sys.maxsize, sys.maxsize, sys.maxsize]\n",
    "    for n, benchmark in enumerate(benchmarks):\n",
    "        print(benchmark)\n",
    "        ax = axs[n]\n",
    "        has_density = \"Sequential\" not in benchmark\n",
    "        ds = densities if has_density else [0.5]\n",
    "        iterate = results3[results3.Benchmark == benchmark].drop(\"Benchmark\", 1)\n",
    "        for density in ds:\n",
    "            if normalizeTo != False:\n",
    "                d = iterate[(iterate.Structure == normalizeTo) & ((has_density == False) | (iterate.Density == 0.5))].Score\n",
    "            iterate2 = iterate\n",
    "            if \"Sequential\" not in benchmark:\n",
    "                iterate2 = iterate2[iterate.Density == density]\n",
    "            iterate2 = iterate2.drop(\"Density\", 1)\n",
    "\n",
    "            for name, group in iterate2.groupby(\"Structure\"):\n",
    "                if normalizeTo != False:\n",
    "                    d.index = group.index\n",
    "                    group.Score = group.Score.div(d, axis=0)\n",
    "                    group.Error = group.Error.div(d, axis=0)\n",
    "                    if name != normalizeTo and stats:\n",
    "                        # If we calculated normal mean and variance they would correspond to log scaled ones.\n",
    "                        # So instead we calculate weighted ones based on the size\n",
    "                        rolld = np.roll(group.Size, 1)\n",
    "                        rolld[0] = 0\n",
    "                        weights = group.Size - rolld\n",
    "                        ssum = np.sum(weights)\n",
    "#                         gmean = np.exp(np.sum(weights * np.log(group.Score)) / ssum)\n",
    "                        mean = np.sum(weights * group.Score) / ssum\n",
    "                        var = np.sum(weights * (group.Score - mean) ** 2) / ssum\n",
    "                        ax.axhline(mean * 100 - 100)\n",
    "#                         ax.axhline(gmean * 100 - 100, ls='-')\n",
    "                        ax.axhline((mean + np.sqrt(var)) * 100 - 100, ls='--')\n",
    "                        ax.axhline((mean - np.sqrt(var)) * 100 - 100, ls='--')\n",
    "                    group.Score = group.Score * 100 - 100\n",
    "                    group.Error = group.Error * 50\n",
    "                maxs[n] = max(maxs[n], np.max(group[\"Score\"]))\n",
    "                mins[n] = min(mins[n], np.min(group[\"Score\"]))\n",
    "                p = group.plot(\n",
    "                    x='Size',\n",
    "                    y='Score',\n",
    "                    logx=logx,\n",
    "                    logy=logy,\n",
    "                    ax=ax,\n",
    "                    label=name + (str(d) if len(ds) > 1 else \"\"),\n",
    "                    title=benchmark,\n",
    "                    zorder=1,\n",
    "                    **get_style(name)\n",
    "                )\n",
    "                p.set(xlabel=\"size\", ylabel=ylabel)\n",
    "                style = get_style(name).copy()\n",
    "                style['lw'] = None\n",
    "                style['linestyle'] = '-'\n",
    "                if error:\n",
    "                    p.fill_between(group.Size, group.Score-group.Error, group.Score+group.Error, alpha=0.4, zorder=0, **style)\n",
    "                if normalizeTo != False:\n",
    "                    p.yaxis.set_major_formatter(mticker.ScalarFormatter())\n",
    "                    p.yaxis.get_major_formatter().set_scientific(False)\n",
    "                # TODO: Include indicator for the point where a data structure overflows different caches\n",
    "        ax.get_legend().remove()\n",
    "        normname = f'Normalized{normalizeTo}' if normalizeTo else ''\n",
    "    padper = 0.05\n",
    "    mx = max(maxs[0], maxs[3], maxs[6])\n",
    "    mn = min(mins[0], mins[3], mins[6])\n",
    "    pad = padper * (mx - mn)\n",
    "    for i in [0, 3, 6]:\n",
    "        axs[i].set_ylim(mn - pad, mx + pad)\n",
    "    mx = max(maxs[1], maxs[4])\n",
    "    mn = min(mins[1], mins[4])\n",
    "    pad = padper * (mx - mn)\n",
    "    for i in [1, 4]:\n",
    "        axs[i].set_ylim(mn - pad, mx + pad)\n",
    "    mx = max(maxs[2], maxs[5])\n",
    "    mn = min(mins[2], mins[5])\n",
    "    pad = padper * (mx - mn)\n",
    "    for i in [2, 5]:\n",
    "        axs[i].set_ylim(mn - pad, mx + pad)\n",
    "    plt.tight_layout()\n",
    "    pos = axs[7].get_position()\n",
    "    fig.delaxes(axs[7])\n",
    "    fig.delaxes(axs[8])\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, bbox_to_anchor=pos, loc='upper left')\n",
    "    plt.savefig(f'./graphs/{filename}.pdf', format='pdf')\n",
    "    if render:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations to compare between different precisions of size parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise(\n",
    "    preciseResults\n",
    "    ,normalizeTo = \"RadixTree\"\n",
    "    ,filename = \"results_radix_precise\"\n",
    "    ,error = True\n",
    "    ,stats = True\n",
    "#     ,logx = False\n",
    "    ,render = False\n",
    ")\n",
    "visualise(\n",
    "    results2[results2.Structure.isin([\"RadixTree\", \"RadixTreeRedux\"])]\n",
    "    ,normalizeTo = \"RadixTree\"\n",
    "    ,filename = \"results_radix\"\n",
    "    ,error = True\n",
    "    ,stats = True\n",
    "#     ,logx = False\n",
    "    ,render = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisations to demonstrate effects of log scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise(\n",
    "    results2[\n",
    "        results2.Structure.isin([\"ScalaV2IntMap\", \"ScalaV2TreeMap\"])\n",
    "    ]\n",
    "    ,normalizeTo = \"ScalaV2TreeMap\"\n",
    "    ,error = False\n",
    "    ,render = False\n",
    "    ,stats = True\n",
    "    ,logx = True\n",
    "    ,filename = \"results_scala_int_tree\"\n",
    ")\n",
    "visualise(\n",
    "    results2[\n",
    "        results2.Structure.isin([\"ScalaV2IntMap\", \"ScalaV2TreeMap\"])\n",
    "    ]\n",
    "    ,normalizeTo = \"ScalaV2TreeMap\"\n",
    "    ,error = False\n",
    "    ,render = False\n",
    "    ,stats = True\n",
    "    ,logx = False\n",
    "    ,filename = \"results_scala_int_tree_nonlog\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playground for trying different visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualise(\n",
    "    results2[\n",
    "#         :\n",
    "#         results2.Structure.isin([\"RadixTree\", \"RadixTreeRedux\"])\n",
    "#         results2.Structure.isin([\"ScalaHashMap\"])#, \"ScalaV2HashMap\"])\n",
    "#         results2.Structure.isin([\"ScalaHashMap\", \"ScalaV2HashMap\", \"IntHamt32Java\", \"IntChamp32Java\"])\n",
    "#         results2.Structure.str.contains(\"ScalaV2\") == False\n",
    "#         results2.Structure.str.contains(\"Scala\") == True\n",
    "#         results2.Structure.isin([\"ScalaHashMap\", \"ScalaV2HashMap\", \"PaguroHashMap\"])\n",
    "        results2.Structure.isin([\"ArrayMap\", \"SdkMap\"]) == False\n",
    "#         results2.Structure.isin([\"ScalaV2RrbMap\", 'PaguroVectorMap', \"ScalaHashMap\", \"ScalaV2HashMap\", \"ScalaV2TreeMap\", \"PaguroHashMap\"])\n",
    "#         results2.Structure.isin([\"ScalaV2IntMap\", \"ScalaV2TreeMap\"])\n",
    "#         results2.Structure.isin(['IntHamt32Java', 'IntHamt32Kotlin'])\n",
    "    ]\n",
    "#     ,normalizeTo = \"RadixTreeRedux\"\n",
    "#     ,normalizeTo = \"IntHamt32Java\"\n",
    "#     ,normalizeTo = \"ScalaV2TreeMap\"\n",
    "    ,normalizeTo = \"ScalaHashMap\"\n",
    "#     ,normalizeTo = \"ScalaIntMap\"\n",
    "#     ,normalizeTo = \"RadixTree\"\n",
    "    ,error = False\n",
    "    ,render = False\n",
    "#     ,stats = True\n",
    "#     ,logx = False\n",
    "#     ,densities=[0.25, 0.5, 0.75]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main routine for generating visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for results, filename, normalizeTo, res in [\n",
    "    (newresults, \"new_server_results_own_hamt\", \"IntHamt32Java\", newresults.Structure.isin([\n",
    "        'IntHamt16Java', 'IntHamt32Java', 'IntHamt64Java'\n",
    "    ])),\n",
    "    (results2, \"results_own_lang\", \"IntHamt32Java\", results2.Structure.isin([\n",
    "        'IntHamt32Java', 'IntHamt32Kotlin', 'IntChamp32Kotlin','IntChamp32Java'\n",
    "    ])),\n",
    "    (results2, \"results_own\", \"IntHamt32Java\", results2.Structure.isin([\n",
    "        'IntHamt32Java', 'IntImplicitKeyHamtKotlin', 'RadixTree', 'RadixTreeRedux'\n",
    "    ])),\n",
    "    (results2, \"results_generic\", \"ScalaHashMap\", results2.Structure.isin([\n",
    "        \"ClojureHashMap\", \"ClojureTreeMap\", \"ScalaHashMap\", \"ScalaV2TreeMap\",\n",
    "        \"ScalaV2HashMap\", \"PaguroHashMap\", \"PaguroTreeMap\"\n",
    "    ])),\n",
    "    (results2, \"results_scala\", \"ScalaHashMap\", results2.Structure.str.contains(\"Scala\") == True),\n",
    "    (results2, \"results_lib_vectors\", \"ScalaV2RrbMap\", results2.Structure.isin([\n",
    "        \"ScalaV2RrbMap\", \"PaguroRrbMap\", \"PaguroVectorMap\", \"ClojureVectorMap\"\n",
    "    ])),\n",
    "    (results2, \"results_specialized\", \"RadixTreeRedux\", results2.Structure.isin([\n",
    "        \"ScalaV2RrbMap\", 'PaguroVectorMap', \"ScalaV2IntMap\", 'IntHamt32Java', 'RadixTreeRedux'\n",
    "    ])),\n",
    "    (results2, \"results_best\", \"ScalaV2TreeMap\", results2.Structure.isin([\n",
    "        \"ScalaV2RrbMap\", 'PaguroVectorMap', \"ScalaV2TreeMap\", \"ScalaHashMap\"\n",
    "    ])),\n",
    "    (results2, \"results_perspective\", \"ScalaV2TreeMap\", results2.Structure.isin([\n",
    "        \"ScalaV2RrbMap\", \"PaguroVectorMap\", \"ScalaHashMap\", \"ScalaV2HashMap\", \"ScalaV2TreeMap\", \"PaguroHashMap\",\n",
    "        \"ArrayMap\", \"SdkMap\"\n",
    "    ]))\n",
    "]:\n",
    "    pd.options.mode.chained_assignment = None\n",
    "    visualise(\n",
    "        results[res],\n",
    "        normalizeTo = normalizeTo,\n",
    "        filename = filename,\n",
    "        render = False,\n",
    "#         error = True,\n",
    "        logx = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
